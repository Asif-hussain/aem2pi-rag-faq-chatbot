# Model Configuration
# Set to 'true' to use local models (Ollama), 'false' to use OpenRouter API
USE_LOCAL_MODEL=false

# OpenRouter API Configuration (only used if USE_LOCAL_MODEL=false)
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=your-openrouter-api-key-here

# API Base URL (do not change unless using different endpoint)
OPENROUTER_API_BASE=https://openrouter.ai

# Embedding Model
# For API (USE_LOCAL_MODEL=false): openai/text-embedding-3-small, openai/text-embedding-3-large
# For Local (USE_LOCAL_MODEL=true): all-minilm, nomic-embed-text, mxbai-embed-large
EMBEDDING_MODEL=openai/text-embedding-3-small

# LLM Model for answer generation
# For API: gpt-3.5-turbo, gpt-4, gpt-4-turbo
# For Local: llama2, mistral, phi
LLM_MODEL=gpt-3.5-turbo

# Evaluator Model (for bonus evaluation agent)
EVALUATOR_MODEL=gpt-3.5-turbo

# Local Model Configuration (only used if USE_LOCAL_MODEL=true)
OLLAMA_BASE_URL=http://localhost:11434
LOCAL_EMBEDDING_MODEL=all-minilm
LOCAL_LLM_MODEL=phi  # Recommended: phi (fast, 10-15s) or llama2 (slower, better quality)

# Number of chunks to retrieve per query
TOP_K=5

# Embedding batch size (for bulk processing)
EMBEDDING_BATCH_SIZE=16
